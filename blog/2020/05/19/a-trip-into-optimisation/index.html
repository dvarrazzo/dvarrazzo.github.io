<!DOCTYPE html>
<html class="no-js">
  <head>
    <meta charset="utf-8">
    <title>A trip into optimisation &mdash; Daniele Varrazzo</title>
    
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-158968242-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-158968242-1');
    </script>
    <link rel="shortcut icon" href="img/favicon.png">
    <link rel="stylesheet" href="/css/plugins.css?h=ee14355f">
    <link href='https://fonts.googleapis.com/css?family=Oswald:400,700,300%7cPoppins:400,300,500,700,600' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" href="/css/main.css?h=af85dcae">
    <link rel="stylesheet" href="/css/syntax.css?h=8242465b">
    <link rel="stylesheet" href="/css/custom.css?h=02992245">
    <script src="/js/lib/modernizr-2.6.2.min.js?h=d0696412"></script>
  </head>

  <body>
    <div class="main-wrapper">
<header id="header" class="">
  <a href="/about/" class="logo">
    <img src="/img/logo.png?h=0ad960b2" class="logo-dark" alt="">
    <img src="/img/logo-light.png?h=cb66caa4" class="logo-light" alt="">
  </a>
  <a href="#" class="mob-menu"><i class="fa fa-bars"></i></a>
  <nav>
    <ul class="main-menu">
<li>
  <a href="/about/">About</a>
</li>
<li>
  <a href="/software/">Software</a>
  <ul>
<li>
  <a href="https://www.psycopg.org/" target="_blank">psycopg <i class="fa fa-external-link" aria-hidden="true"></i></a>
</li>
<li>
  <a href="https://www.varrazzo.com/pgmp/" target="_blank">pgmp <i class="fa fa-external-link" aria-hidden="true"></i></a>
</li>
<li>
  <a href="https://pgxn.github.io/pgxnclient/" target="_blank">PGXN Client <i class="fa fa-external-link" aria-hidden="true"></i></a>
</li>
<li>
  <a href="https://reorg.github.io/pg_repack/" target="_blank">pg_repack <i class="fa fa-external-link" aria-hidden="true"></i></a>
</li>
  </ul>
</li>
<li>
  <a href="/photo/">Photography</a>
  <ul>
<li>
  <a href="/photo/longexp/">Long exposures</a>
</li>
<li>
  <a href="/photo/gaeta-2021/">A Window on the Sea, 2021</a>
</li>
<li>
  <a href="/photo/whangarei/">Isolation diaries, 2020</a>
</li>
<li>
  <a href="/photo/ireland/">Ireland, 2019</a>
</li>
<li>
  <a href="/photo/japan/">Japan, 2019</a>
</li>
  </ul>
</li>
<li>
  <a href="/blog/">Blog</a>
</li>
<li>
  <a href="/contact/">Contact</a>
</li>
    </ul>
  </nav>
</header>
<div class="container fullwidth pt140 pb140" data-background="/img/blog/aisle.jpg?h=d4e8393f">
  <div class="pt140 pb140">
    <div class="entrance">
      <h2 class="title">A trip into optimisation</h2>
      <p class="separator"></p>
      <p class="small capitalize serif">2020-05-19</p>
      
        <div class="bumper">
          <p class="small">
          
            <a href="/blog/tag/software/">#software</a>
          
            <a href="/blog/tag/psycopg/">#psycopg</a>
          
            <a href="/blog/tag/development/">#development</a>
          
          </p>
        </div>
      
    </div>
  </div>
</div>

<div class="container mt70 mb70">
  <div class="row">
    <div id="content" class="col-md-9">

      
      <div class="admonition admonition-sponsor">
        <p>
        The <a href="https://psycopg.org/psycopg3" target="_blank"
          >psycopg3 project</a>
        is currently
        <a href="https://github.com/psycopg/psycopg3" target="_blank"
          >under active development</a>.
        </p>

        <p>
        Sponsoring this project will help achieve swift completion and
        ensure the maintenance of psycopg2, psycopg3 and other related
        projects.
        </p>

        <p>
        If you use Python and PostgreSQL, and you would like to support the
        creation of the most advanced adapter between the two systems,
        <a href="https://github.com/sponsors/dvarrazzo/" target="_blank"
          >please consider becoming a sponsor</a>. Thank you!
        </p>

        <iframe src="https://github.com/sponsors/dvarrazzo/button"
                title="Sponsor the project" style="border: 0"
                width="116" height="35">
        </iframe>
      </div>
      <p>I have been cheerfully hacking on psycopg3 features for a while and reached
the symbolic but relevant milestone of <a class="reference external" href="https://github.com/psycopg/psycopg3/commit/be4e3ee85dc773878d67edf0b7880824bf7059aa">DBAPI 2.0 compatibility</a> while using
the psycopg2 test suite as a guideline to add features progressively.</p>
<p>Then I thought about checking its speed... It wasn't a happy day.</p>
<p>A few years ago, a new PostgreSQL driver was released: <a class="reference external" href="https://magicstack.github.io/asyncpg/">asyncpg</a>. It is
designed with speed in mind, at the expense of much else. It parses the
<a class="reference external" href="https://www.postgresql.org/docs/current/protocol.html">PostgreSQL frontend/backend protocol</a> using its own implementation (instead
of using <a class="reference external" href="https://www.postgresql.org/docs/current/libpq.html">libpq</a>, the PostgreSQL client library) and is designed to be pretty
much streamlined within the flow of the line protocol rather than have a
developer-friendly or recognisable interface: it doesn't follow a <a class="reference external" href="https://www.python.org/dev/peps/pep-0249/">DBAPI</a>
design, it uses PostgreSQL native placeholders for queries, i.e. <tt class="docutils literal">where
someting = $1</tt>, no positional or named ones (the familiar <tt class="docutils literal">%s</tt> and
<tt class="docutils literal">%(thing)s</tt>). It is definitely a fast library, but much like a Formula 1
car, it's not for everyone to drive. Dropping it in your existing project
means having to rewrite all your queries and all the Python code interacting
with the database: no Django, no SQLAlchemy, and of course it's only
asynchronous, so not the natural choice if your program uses a different
concurrency model or needs none at all.</p>
<p>Anyway I thought I'd use <a class="reference external" href="https://github.com/magicstack/pgbench">the toolbench they wrote</a> to compare speeds between
psycopg2 and asyncpg. So how bad was my day?</p>
<!-- for d in asyncpg aiopg-tuples psycopg3-async; do \
    python pgbench_python.py $d -C1 ../queries/1-pg_type.json -D 10 - -warmup-time 1 \
    - - -pghost localhost - -pgport 5432 - -pguser piro - -output-format json \
    | jq -j "\"$d \" ,  .queries , \"\n\"" ; \
done -->
<table border="1" class="docutils">
<colgroup>
<col width="70%" />
<col width="30%" />
</colgroup>
<thead valign="bottom">
<tr><th class="head">Driver</th>
<th class="head">Queries</th>
</tr>
</thead>
<tbody valign="top">
<tr><td>asyncpg</td>
<td>15263</td>
</tr>
<tr><td>psycopg2 + aiopg</td>
<td>8871</td>
</tr>
<tr><td>psycopg3 async</td>
<td>426</td>
</tr>
</tbody>
</table>
<p>It was this bad.</p>
<p>This is the number of queries that are run in 10 seconds. The numbers
themselves are to be taken with a fistful of salt. Essentially they are
obtaining connecting to a database on localhost so they are more CPU-bound
than the environment a database driver usually lives in. They come from <em>one
specific query</em> (the first in their toolbench) so nothing statistically sound,
but still a pretty depressing picture.</p>
<p>Back then, the implementation of psycopg3 was pure Python, using ctypes to call
into the libpq shared library. The plan to write an optimised C
implementation was already there, but this made me understand how badly needed
this is.</p>
<div class="section" id="profiling">
<h3>Profiling</h3>
<p>The first step to climb such a mountain is to look at profiling information,
which can show function by function where time is spent.</p>
<div class="figure align-center">
<a class="reference external image-reference" href="profile-7b3b7f9.svg"><img alt="profile-7b3b7f9.png" src="profile-7b3b7f9.png" /></a>
<p class="caption">Profile graph at commit <tt class="docutils literal">7b3b7f9</tt></p>
</div>
<p>The graph is generated by <a class="reference external" href="https://github.com/jrfonseca/gprof2dot">gprof2dot</a> using something like:</p>
<pre class="code bash literal-block">
python<span class="w"> </span>-m<span class="w"> </span>cProfile<span class="w"> </span>-o<span class="w"> </span>OUT.pstat<span class="w"> </span>script.py<span class="w">
</span>gprof2dot<span class="w"> </span>-f<span class="w"> </span>pstats<span class="w"> </span>OUT.pstat<span class="w"> </span><span class="p">|</span><span class="w"> </span>dot<span class="w"> </span>-Tsvg<span class="w"> </span>&gt;<span class="w"> </span>OUT.svg
</pre>
<!-- python -m cProfile -o psycopg3-async.pstat pgbench_python.py psycopg3-async \
    -C1 ../queries/1-pg_type.json -D 10 - -warmup-time 1 \
    - - -pghost localhost - -pgport 5432 - -pguser piro - -output-format json
gprof2dot -f pstats psycopg3-async.pstat | dot -Tsvg > psycopg3-async-prof.svg -->
<p>You can see more details by clicking on the above graph. The left branch is
initialisation faff. The interesting part is on the right, following the path
of orange, yellow and green. This shows the functions calls where the program
spends most of its time. <tt class="docutils literal">get_value</tt> is a pretty hot one, taking up about
the 50% of the run time. It gets called very often, once per field of every
record, or 1.6M times in this graph. At this point, it looked like this:</p>
<pre class="code python literal-block">
<span class="k">def</span> <span class="nf">get_value</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">row_number</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">column_number</span><span class="p">:</span> <span class="nb">int</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bytes</span><span class="p">]:</span><span class="w">
</span>    <span class="n">length</span> <span class="o">=</span> <span class="n">impl</span><span class="o">.</span><span class="n">PQgetlength</span><span class="p">(</span><span class="w">
</span>        <span class="bp">self</span><span class="o">.</span><span class="n">pgresult_ptr</span><span class="p">,</span> <span class="n">row_number</span><span class="p">,</span> <span class="n">column_number</span><span class="w">
</span>    <span class="p">)</span><span class="w">
</span>    <span class="k">if</span> <span class="n">length</span><span class="p">:</span><span class="w">
</span>        <span class="n">v</span> <span class="o">=</span> <span class="n">impl</span><span class="o">.</span><span class="n">PQgetvalue</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pgresult_ptr</span><span class="p">,</span> <span class="n">row_number</span><span class="p">,</span> <span class="n">column_number</span><span class="p">)</span><span class="w">
</span>        <span class="k">return</span> <span class="n">string_at</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">length</span><span class="p">)</span><span class="w">
</span>    <span class="k">else</span><span class="p">:</span><span class="w">
</span>        <span class="k">if</span> <span class="n">impl</span><span class="o">.</span><span class="n">PQgetisnull</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pgresult_ptr</span><span class="p">,</span> <span class="n">row_number</span><span class="p">,</span> <span class="n">column_number</span><span class="p">):</span><span class="w">
</span>            <span class="k">return</span> <span class="kc">None</span><span class="w">
</span>        <span class="k">else</span><span class="p">:</span><span class="w">
</span>            <span class="k">return</span> <span class="sa">b</span><span class="s2">&quot;&quot;</span>
</pre>
<p>This function returns the content in bytes of a field. If it's 0-length, it
checks if it's NULL. The <tt class="docutils literal">impl</tt> functions are ctypes calls to the libpq.
This made me think that the overhead of ctypes calls is not so tiny after
all.</p>
</div>
<div class="section" id="the-cffi-attempt">
<h3>The cffi attempt</h3>
<p>One thing I thought about doing was also to provide a <a class="reference external" href="https://cffi.readthedocs.io/">cffi</a> wrapper for the
libpq. cffi is a more popular choice than ctypes, especially thanks to its
good integration with PyPy. ctypes has the advantage of being packaged in the
standard library, so not requiring an external dependency. However, unlike
ctypes, cffi still requires a compiler to create a more efficient wrapper.</p>
<p>Porting the libpq wrapper to cffi was relatively straightforward and the
number of queries that ran was more than double:</p>
<table border="1" class="docutils">
<colgroup>
<col width="50%" />
<col width="25%" />
<col width="25%" />
</colgroup>
<thead valign="bottom">
<tr><th class="head">Implementation</th>
<th class="head">Commit</th>
<th class="head">Queries</th>
</tr>
</thead>
<tbody valign="top">
<tr><td>ctypes</td>
<td>7b3b7f9</td>
<td>426</td>
</tr>
<tr><td>cffi</td>
<td>dfe2893</td>
<td>902</td>
</tr>
</tbody>
</table>
<p><a class="reference external" href="profile-cffi-dfe2893.svg">Profiling</a> showed that the time spent in <tt class="docutils literal">get_value</tt> was down from 50% to
35%, suggesting that the cffi overhead is lower than ctypes. However,
building a cffi wrapper already requires the presence of a C compiler, the
<tt class="docutils literal"><span class="pre">libpq-dev</span></tt> package and finding the dreaded <tt class="docutils literal">pg_config</tt> executable: the
same requirements a C extension implementation would have, but with less
possibilities for optimisation. For this reason, cffi will probably remain as
a thing on the side (maybe if the PyPy folks would be interested in it). This
code is now parked <a class="reference external" href="https://github.com/psycopg/psycopg3/tree/cffi">in its own branch</a>.</p>
</div>
<div class="section" id="the-cython-attempt">
<h3>The Cython attempt</h3>
<p>The next and more reasonable way to improve performance is to create a C
extension. As highlighted in <a class="reference external" href="/blog/2020/03/06/thinking-psycopg3/">Thinking psycopg3</a>, the idea was
already in place, allowing the user to choose between the simple to install
option or the fast option. A Python C extension can be written in pure C, as
psycopg2 currently is, but there are other languages helping to handle some of
the tedious aspects, such as the boilerplate required to create the objects,
and the reference count. The most current of such languages is <a class="reference external" href="https://cython.readthedocs.io/">Cython</a>, an
evolution of <a class="reference external" href="https://www.cosc.canterbury.ac.nz/greg.ewing/python/Pyrex/">Pyrex</a>, which I had once used a ridiculous number of years ago.</p>
<p>The first step was a straightforward porting of the <tt class="docutils literal">psycogp3.pq</tt> module:
that alone showed a promising class of results:</p>
<table border="1" class="docutils">
<colgroup>
<col width="50%" />
<col width="25%" />
<col width="25%" />
</colgroup>
<thead valign="bottom">
<tr><th class="head">Implementation</th>
<th class="head">Commit</th>
<th class="head">Queries</th>
</tr>
</thead>
<tbody valign="top">
<tr><td>ctypes</td>
<td>7b3b7f9</td>
<td>426</td>
</tr>
<tr><td>cffi</td>
<td>dfe2893</td>
<td>902</td>
</tr>
<tr><td>Cython pq</td>
<td>6c6cbe3</td>
<td>1618</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="speeding-up-adaptation">
<h3>Speeding up adaptation</h3>
<p><a class="reference external" href="profile-c-6c6cbe3.svg">New profiling</a> showed that the time spent in <tt class="docutils literal">get_value()</tt> was now reduced
to a paltry 6% of the whole runtime: this means that that the hot path of the
program had moved to a different place.</p>
<p>The entire adaptation of the returned dataset, visible in green, takes 60% of
the runtime, so is a likely next candidate for optimisation. The <tt class="docutils literal">&lt;genexpr&gt;</tt>
box is shown having a large number of called functions: that function is the
dispatcher choosing a different adapter function for each PostgreSQL data
type, which were still written in Python.</p>
<p>There is probably some value in creating analogous conversion functions in C,
but it wouldn't be the best way to optimise the job. All the loader functions
have the same signature, for instance: the loader for the binary
representation of a 32 bits integer is:</p>
<pre class="code python literal-block">
<span class="n">_int4_struct</span> <span class="o">=</span> <span class="n">struct</span><span class="o">.</span><span class="n">Struct</span><span class="p">(</span><span class="s2">&quot;!i&quot;</span><span class="p">)</span><span class="w">

</span><span class="k">def</span> <span class="nf">load_int4_binary</span><span class="p">(</span><span class="n">data</span><span class="p">:</span> <span class="nb">bytes</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span><span class="w">
</span>    <span class="k">return</span> <span class="n">_int4_struct</span><span class="o">.</span><span class="n">unpack</span><span class="p">(</span><span class="n">data</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
</pre>
<p>In order to feed data to this function it is necessary to:</p>
<ul class="simple">
<li>get the pointer and length to the returned data from the <tt class="docutils literal">PGresult</tt>
struct (calls to <tt class="docutils literal">PQgetvalue</tt> and <tt class="docutils literal">PQgetlength</tt>, which are lightweight);</li>
<li>convert it to a Python <tt class="docutils literal">bytes</tt> object, meaning a <tt class="docutils literal">memcpy</tt> and a Python
object allocation;</li>
<li>calling the adaptation function (Python or C).</li>
</ul>
<p>If we decide not to leave the C layer in the adaptation phase then a better
signature can be used:</p>
<pre class="code pyrex literal-block">
<span class="k">cdef</span> <span class="kt">object</span> <span class="nf">load_int4_binary_c</span><span class="p">(</span><span class="n">const</span> <span class="n">char</span> <span class="o">*</span><span class="n">data</span><span class="p">,</span> <span class="n">size_t</span> <span class="n">length</span><span class="p">,</span> <span class="n">void</span> <span class="o">*</span><span class="n">context</span><span class="p">):</span><span class="w">
</span>    <span class="k">return</span> <span class="n">PyLong_FromLong</span><span class="p">(</span><span class="o">&lt;</span><span class="n">int32_t</span><span class="o">&gt;</span><span class="n">be32toh</span><span class="p">((</span><span class="o">&lt;</span><span class="n">uint32_t</span> <span class="o">*&gt;</span><span class="n">data</span><span class="p">)[</span><span class="mf">0</span><span class="p">]))</span>
</pre>
<p>This allows for reaching of the loader functions without the need of an extra
copy of the data received from the network and without creating an
intermediate Python object. However, because the C functions are not
accessible from Python, it poses the question of how to customise the adapters
mapping, in case someone wanted to replace a builtin one (a typical case
involves wanting to convert <tt class="docutils literal">numeric</tt> into Python <tt class="docutils literal">float</tt> instead of
<tt class="docutils literal">Decimal</tt>). For now, the mechanism works like this:</p>
<ul>
<li><p class="first">At import time, the Python adapters are associated to data types OIDs; the
current mechanism is through a decorator:</p>
<pre class="code python literal-block">
<span class="c1"># in psycopg3/types/numeric.py</span><span class="w">

</span><span class="nd">&#64;Loader</span><span class="o">.</span><span class="n">binary</span><span class="p">(</span><span class="n">builtins</span><span class="p">[</span><span class="s2">&quot;int4&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">oid</span><span class="p">)</span><span class="w">
</span><span class="k">def</span> <span class="nf">load_int4_binary</span><span class="p">(</span><span class="n">data</span><span class="p">:</span> <span class="nb">bytes</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span><span class="w">
</span>    <span class="k">return</span> <span class="n">_int4_struct</span><span class="o">.</span><span class="n">unpack</span><span class="p">(</span><span class="n">data</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
</pre>
</li>
<li><p class="first">If the C extension module is to be used, a C function exposed to Python is
called, <tt class="docutils literal">register_builtin_c_loaders()</tt>.</p>
<pre class="code python literal-block">
<span class="c1"># in psycopg3/__init__.py</span><span class="w">

</span><span class="c1"># register default adapters</span><span class="w">
</span><span class="kn">from</span> <span class="nn">.</span> <span class="kn">import</span> <span class="n">types</span><span class="w">

</span><span class="c1"># Override adapters with fast version if available</span><span class="w">
</span><span class="k">if</span> <span class="n">pq</span><span class="o">.</span><span class="n">__impl__</span> <span class="o">==</span> <span class="s2">&quot;c&quot;</span><span class="p">:</span><span class="w">
</span>    <span class="kn">from</span> <span class="nn">._psycopg3</span> <span class="kn">import</span> <span class="n">register_builtin_c_loaders</span><span class="w">
</span>    <span class="n">register_builtin_c_loaders</span><span class="p">()</span>
</pre>
</li>
<li><p class="first">This in turns calls a registration
function for all the loaders, for which there is a C implementation:</p>
<pre class="code pyrex literal-block">
<span class="c"># in psycopg3/types/numeric.pyx</span><span class="w">

</span><span class="k">from</span> <span class="nn">psycopg3.types</span> <span class="k">import</span> <span class="n">numeric</span><span class="w">
</span><span class="n">register_c_loader</span><span class="p">(</span><span class="n">numeric</span><span class="o">.</span><span class="n">load_int4_binary</span><span class="p">,</span> <span class="n">load_int4_binary_c</span><span class="p">)</span>
</pre>
</li>
<li><p class="first">When the result of a query is returned to the client, the OIDs of the
columns are used to select a Python loader. In Python, the loaders are put
into a list, having as many items as the columns number. In Cython, they are
put into a C array of structures holding both a Python function and
optionally a C function as members. If a Python loader has an optimised
version registered then that function is added to the array of loaders.</p>
<table border="1" class="docutils">
<colgroup>
<col width="12%" />
<col width="6%" />
<col width="39%" />
<col width="43%" />
</colgroup>
<thead valign="bottom">
<tr><th class="head">Type</th>
<th class="head">OID</th>
<th class="head">Python loader</th>
<th class="head">C loader</th>
</tr>
</thead>
<tbody valign="top">
<tr><td>text</td>
<td>25</td>
<td><tt class="docutils literal">load_text_binary</tt></td>
<td><tt class="docutils literal">load_text_binary_c</tt></td>
</tr>
<tr><td>int4</td>
<td>23</td>
<td><tt class="docutils literal">load_int4_binary</tt></td>
<td><tt class="docutils literal">load_int4_binary_c</tt></td>
</tr>
<tr><td>custom</td>
<td>??</td>
<td><tt class="docutils literal">load_custom_type</tt></td>
<td><tt class="docutils literal">NULL</tt></td>
</tr>
</tbody>
</table>
</li>
<li><p class="first">When the data is converted to Python, the corresponding
loader is used for each column:</p>
<ul class="simple">
<li>if it has a C loader, the value and lengths are read from the result and
passed to the function;</li>
<li>if it doesn't have one, a <tt class="docutils literal">bytes</tt> object is created and passed to the Python
function.</li>
</ul>
</li>
</ul>
<p>This mechanism allows for the overriding of the mapping from OID to types in
Python, which is then duplicated in C. It has the disadvantage that if someone
wanted to derive an adapter for a custom data type (e.g. calling the text
adapter and then parsing the result) then the Python adapter would be used.
There is probably possibility to improve this design, but it is a good
starting point for now.</p>
<p>It <em>might</em> be possible to avoid <tt class="docutils literal">memcpy</tt> by creating a memory view
instead of a bytes array, but I haven't quite figured out how to do it in
ctypes yet.</p>
<p>Numbers, now, start to appear more promising:</p>
<table border="1" class="docutils">
<colgroup>
<col width="50%" />
<col width="25%" />
<col width="25%" />
</colgroup>
<thead valign="bottom">
<tr><th class="head">Implementation</th>
<th class="head">Commit</th>
<th class="head">Queries</th>
</tr>
</thead>
<tbody valign="top">
<tr><td>ctypes</td>
<td>7b3b7f9</td>
<td>426</td>
</tr>
<tr><td>cffi</td>
<td>dfe2893</td>
<td>902</td>
</tr>
<tr><td>Cython pq</td>
<td>6c6cbe3</td>
<td>1618</td>
</tr>
<tr><td>Cython adapt</td>
<td>b28b389</td>
<td>7511</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="profiling-against-psycopg2">
<h3>Profiling against psycopg2</h3>
<p>I was having concerns for a while that there was something stupidly wrong in
my psycopg3 code, especially around the networking area, for instance
introducing delays waiting the wrong way or at the wrong moment. asyncpg is
too radically different to provide a direct comparison, but a comparison with
psycopg2 would have been interesting. Unfortunately, because psycopg2 is
written in pure C code, it doesn't allow inspection using the Python profiler
(Cython extensions are C too, but they can create explicit hooks for that).
But where a tracing profiler cannot trace, a sampling profiler can sample:
<a class="reference external" href="https://github.com/benfred/py-spy">py-spy</a> is such a profiler. The principle is to interrupt a process several
times per second to look at its call stack and infer what it is doing.
Provided enough debug information is compiled in the C library, it is possible
to obtain clear information about calls into C code too. And of course, the
most important feature good software should always have: the production of
pretty graphs:</p>
<div class="figure align-center">
<a class="reference external image-reference" href="flame-psycopg3-b662c9d.svg?x=7.7301%25&amp;y=196"><img alt="flame-psycopg3-b662c9d.png" src="flame-psycopg3-b662c9d.png" /></a>
<p class="caption"><a class="reference external" href="http://www.brendangregg.com/flamegraphs.html">Flame graph</a> for psycopg3 at commit <tt class="docutils literal">b662c9d</tt>. Come and click around:
it's interactive! 🍬</p>
<div class="legend">
</div>
</div>
<div class="figure align-center">
<a class="reference external image-reference" href="flame-psycopg2-2.8.5.svg?x=12.2885%25&amp;y=196"><img alt="flame-psycopg2-2.8.5.png" src="flame-psycopg2-2.8.5.png" /></a>
<p class="caption">Flame graph for psycopg2 2.8.5.</p>
</div>
<!-- for d in aiopg-tuples psycopg3-async; do
    py-spy record -r 500 -o $d.svg -F - -native - - python pgbench_python.py $d \
        -C1 ../queries/1-pg_type.json -D 10 - -warmup-time 1 \
        - - -pghost localhost - -pgport 5432 - -pguser piro - -output-format json;
done -->
<p>This comparison shows that the time around the libpq is roughly comparable
(psycopg2 calls the chubby <tt class="docutils literal">pqParseInput3</tt> as a consequence of calling
<tt class="docutils literal">PQnotifies</tt>; for psycopg3, it happens in <tt class="docutils literal">PQisBusy</tt> because it currently
lacks a notifications handler). There was actually <a class="reference external" href="https://github.com/psycopg/psycopg3/commit/f9bd81d7e61628f619f39d399532fc4dedfab256">a bug</a> in the fetching
loop, but because of that bug, the code was actually running somewhat
faster (it would have likely hurt concurrent performance with blocking
though).</p>
</div>
<div class="section" id="current-state-future-improvements">
<h3>Current state, future improvements</h3>
<p>The diagrams above suggest that there is still room for improvement:
<tt class="docutils literal">fetchall()</tt> seems to have some overhead, which can probably be reduced by
introducing a &quot;fetchsome&quot; function in C. There is a lot of overhead around
waiting, especially in the process of registering/unregistering listeners: the
best gains seem achievable here, bypassing some of the <tt class="docutils literal">asyncio</tt> machinery and creating a better integration with the underlying reactor.</p>
<p>Below are the bottom line figures, as of the current <tt class="docutils literal">master</tt> (<tt class="docutils literal">b662c9d</tt>).
The pure Python results have improved too, thanks to the Python code tweaking
since the first test:</p>
<table border="1" class="docutils">
<colgroup>
<col width="75%" />
<col width="25%" />
</colgroup>
<thead valign="bottom">
<tr><th class="head">Driver</th>
<th class="head">Queries</th>
</tr>
</thead>
<tbody valign="top">
<tr><td>asyncpg</td>
<td>15263</td>
</tr>
<tr><td>psycopg2 + aiopg</td>
<td>8871</td>
</tr>
<tr><td>psycopg3 async Python</td>
<td>517</td>
</tr>
<tr><td>psycopg3 async C</td>
<td>8424</td>
</tr>
</tbody>
</table>
<p>Again, this is just a rough indication: the data types in the query and
different concurrency patterns create different pictures. For instance,
psycopg3 is already faster than psycopg2 in benchmarks involving <tt class="docutils literal">bytea</tt>,
thanks to the use of the binary protocol:</p>
<table border="1" class="docutils">
<colgroup>
<col width="70%" />
<col width="30%" />
</colgroup>
<thead valign="bottom">
<tr><th class="head">Driver</th>
<th class="head">Queries</th>
</tr>
</thead>
<tbody valign="top">
<tr><td>asyncpg</td>
<td>41330</td>
</tr>
<tr><td>psycopg2 + aiopg</td>
<td>12396</td>
</tr>
<tr><td>psycopg3 async C</td>
<td>19164</td>
</tr>
</tbody>
</table>
<p>I think for the moment, the search for speed can be concluded and it is time to
go back to progressing with the features. I doubt that asyncpg's stellar
performances can be passed, but I don't want performance to be the sole goal:
I am fine with psycopg3 being somewhat slower than asyncpg, if it has the
advantage to be easier to use and to behave pretty much as a drop-in
replacement for psycopg2. In my view, a driver with a lower adoption barrier
would be more directly beneficial for everyone wanting to use it, either in
existing frameworks or on its own. By the time the project will be released,
I am confident that its performance will consistently pass the psycopg2 level.</p>
</div>

<script src="https://utteranc.es/client.js"
  repo="dvarrazzo/www.varrazzo.com"
  issue-term="pathname"
  label="comments"
  theme="github-light"
  crossorigin="anonymous"
  async>
</script>
    </div>
    <div id="sidebar" class="col-md-3">
<div class="sidebar-inner">
  <div class="widget-area">
<aside class="widget">
  <h3 class=widget-title>Recent posts</h3>
  <ul>
    <li><a href="/blog/2021/03/05/gaeta-2021/">A window on the sea</a></li>
    <li><a href="/blog/2020/11/07/psycopg3-adaptation/">psycopg3 and adaptation choices</a></li>
    <li><a href="/blog/2020/07/25/surviving-django/">Surviving Django (if you care about databases)</a></li>
    <li><a href="/blog/2020/05/19/a-trip-into-optimisation/">A trip into optimisation</a></li>
    <li><a href="/blog/2020/04/26/pinhole-day/">Pinhole Day</a></li>
  </ul>
</aside>
<aside class="widget">
  <h3 class=widget-title>Tags</h3>
  <ul>
<li><a href="/blog/tag/database/">#database</a></li>
<li><a href="/blog/tag/design/">#design</a></li>
<li><a href="/blog/tag/development/">#development</a></li>
<li><a href="/blog/tag/life/">#life</a></li>
<li><a href="/blog/tag/news/">#news</a></li>
<li><a href="/blog/tag/photo/">#photo</a></li>
<li><a href="/blog/tag/pinhole/">#pinhole</a></li>
<li><a href="/blog/tag/psycopg/">#psycopg</a></li>
<li><a href="/blog/tag/software/">#software</a></li>
<li><a href="/blog/tag/travel/">#travel</a></li>
<li><a href="/blog/tag/website/">#website</a></li>
  </ul>
</aside>
  </div>
</div>
    </div>
</div>

<footer id="footer" class="">
  <div class="footer-links">
    &copy; 2020-2021. By Daniele Varrazzo. |
    <a target="_blank" href="https://github.com/dvarrazzo/">GitHub</a> |
    <a target="_blank" href="https://www.linkedin.com/in/danielevarrazzo/">LinkedIn</a> |
    <a target="_blank" href="https://www.instagram.com/dvarrazzo/">Instagram</a> |
    <a target="_blank" href="https://www.flickr.com/photos/dvarrazzo/albums/72157627599162127">Flickr</a>
  </div>

</footer>
    </div>
    <script src="/js/lib/jquery.min.js?h=d6c1f419"></script>
    <script src="/js/lib/scripts.js?h=e59b43e0"></script>
    <script src="/js/main.js?h=4b3e78de"></script>
  </body>
</html>
